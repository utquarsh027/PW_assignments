{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323fbbb7",
   "metadata": {},
   "source": [
    "#### Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53061be0",
   "metadata": {},
   "source": [
    "Bayes' Theorem states that the probability of a event A happening when another event B has already happened is equals to the probability of A multiplied by probabilty of happedning of event B when A has occurred divided by probability of event B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575e4fc1",
   "metadata": {},
   "source": [
    "#### Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be879ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(A|B)=(P(A)*P(B|A)/P(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d63dc0",
   "metadata": {},
   "source": [
    "#### Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71cd10e",
   "metadata": {},
   "source": [
    "- Medical diagnosis: A doctor might use Bayes' theorem to calculate the probability that a patient has a particular disease based on the patient's symptoms, medical history, and the results of diagnostic tests. For example, a doctor might use Bayes' theorem to calculate the probability that a patient has cancer based on the patient's age, sex, family history, and the results of a mammogram.\n",
    "- Spam filtering: A spam filter might use Bayes' theorem to calculate the probability that an email is spam based on the words in the email, the sender's email address, and other factors. For example, a spam filter might give a higher probability of being spam to an email that contains the words \"free money\" and \"click here.\"\n",
    "- Image recognition: An image recognition system might use Bayes' theorem to identify the objects in an image. For example, an image recognition system might use Bayes' theorem to identify the cat in a photo of a cat sitting on a couch.\n",
    "- Natural language processing: A natural language processing system might use Bayes' theorem to translate text from one language to another. For example, a natural language processing system might use Bayes' theorem to translate the sentence \"I love cats\" from English to Spanish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50207cd7",
   "metadata": {},
   "source": [
    "#### Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690b70df",
   "metadata": {},
   "source": [
    "Bayes' theorem is a mathematical formula that relates two conditional probabilities. Conditional probability is the probability of one event occurring given that another event has already occurred.\n",
    "\n",
    "Bayes' theorem can be expressed in the following formula:\n",
    "\n",
    "```\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "```\n",
    "\n",
    "where:\n",
    "\n",
    "* P(A|B) is the probability of event A occurring given that event B has already occurred.\n",
    "* P(B|A) is the probability of event B occurring given that event A has already occurred.\n",
    "* P(A) is the probability of event A occurring regardless of whether or not event B has occurred.\n",
    "* P(B) is the probability of event B occurring regardless of whether or not event A has occurred.\n",
    "\n",
    "In other words, Bayes' theorem tells us how to update our beliefs about the probability of an event A given that we have observed new evidence B.\n",
    "\n",
    "Bayes' theorem is derived from the definition of conditional probability. To see this, we can start with the definition of conditional probability:\n",
    "\n",
    "```\n",
    "P(A|B) = P(A and B) / P(B)\n",
    "```\n",
    "\n",
    "where P(A and B) is the probability of both events A and B occurring.\n",
    "\n",
    "We can also write the joint probability P(A and B) as:\n",
    "\n",
    "```\n",
    "P(A and B) = P(B|A) * P(A)\n",
    "```\n",
    "\n",
    "where P(B|A) is the probability of event B occurring given that event A has already occurred and P(A) is the probability of event A occurring regardless of whether or not event B has occurred.\n",
    "\n",
    "Substituting this into the definition of conditional probability, we get:\n",
    "\n",
    "```\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "```\n",
    "\n",
    "which is Bayes' theorem.\n",
    "\n",
    "Bayes' theorem is a powerful tool for updating our beliefs about the world in light of new evidence. It is used in a wide variety of fields, including medicine, machine learning, and artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ceed0",
   "metadata": {},
   "source": [
    "#### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a458a7",
   "metadata": {},
   "source": [
    "\n",
    "The type of Naive Bayes classifier to use for any given problem depends on the nature of the data.\n",
    "\n",
    "- Gaussian Naive Bayes: Gaussian Naive Bayes is used when the features in the data are continuous and follow a Gaussian distribution. For example, Gaussian Naive Bayes could be used to classify emails as spam or not spam based on the length of the email, the number of attachments, and the sender's email address.\n",
    "- Multinomial Naive Bayes: Multinomial Naive Bayes is used when the features in the data are discrete and count data. For example, Multinomial Naive Bayes could be used to classify documents as news articles or blog posts based on the words in the documents.\n",
    "- Bernoulli Naive Bayes: Bernoulli Naive Bayes is used when the features in the data are binary (i.e., yes or no). For example, Bernoulli Naive Bayes could be used to classify images as containing a cat or not containing a cat based on the presence or absence of certain features in the images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cefd27",
   "metadata": {},
   "source": [
    "#### Q.6 You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "- X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "- A 3 3 4 4 3 3 3\n",
    "- B 2 2 1 2 2 2 3\n",
    "\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bded7c3b",
   "metadata": {},
   "source": [
    "Plugging in the values from the frequency table, we get the following probabilities:\n",
    "\n",
    "- For class A:\n",
    "  - P(A | X1 = 3, X2 = 4) = (4/13 * 3/13 * 7/14) / (4/13 * 3/13 * 7/14 + 1/7 * 3/7 * 7/14)\n",
    "  - P(A | X1 = 3, X2 = 4) = **0.36**\n",
    "\n",
    "- For class B:\n",
    "  - P(B | X1 = 3, X2 = 4) = (1/7 * 3/7 * 7/14) / (4/13 * 3/13 * 7/14 + 1/7 * 3/7 * 7/14)\n",
    "  - P(B | X1 = 3, X2 = 4) = **0.64**\n",
    "\n",
    "Therefore, Naive Bayes would predict the new instance to belong to **class B**, since it has a higher probability than class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe061cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb60ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
